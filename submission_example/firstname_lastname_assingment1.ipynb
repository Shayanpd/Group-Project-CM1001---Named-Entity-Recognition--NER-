{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: This is the title of the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors:  \n",
    "Shayan Paydar Darian and \n",
    "Daniel Pazirai \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# It is recommended to start with general import statements\n",
    "from utility_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section should load the raw dataset for the task.  \n",
    "Remember to use relative paths to load any files in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the Swedish Medical NER dataset\n",
    "\n",
    "# Check the dataset structure\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Survey (kolla upp vilka modeller som finns och kolla vilken LLN som är bäst för Swedish Biomedical NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey of Models for Swedish Biomedical NER\n",
    "\n",
    "| **Model**        | **Language(s)** | **Strengths**                                   | **Weaknesses**                                  | **Relevance for Biomedical NER (Swedish)**               |\n",
    "|------------------|-----------------|-------------------------------------------------|-------------------------------------------------|----------------------------------------------------------|\n",
    "| **KB-BERT**      | Swedish         | Native Swedish, decent at general NER tasks     | No biomedical pretraining                       | Good starting point                                      |\n",
    "| **Swedish ALBERT** | Swedish       | Lightweight, faster to train                    | Lacks domain specialization                    | OK, but may miss nuances                                 |\n",
    "| **mBERT**        | Multilingual    | Cross-lingual abilities                         | Not optimized for any specific language/domain | Medium                                                   |\n",
    "| **XLM-RoBERTa**  | Multilingual    | Robust multilingual understanding               | Same as mBERT, no biomedical specialization    | Medium                                                   |\n",
    "| **BioBERT (English)** | English    | Biomedical domain specialized                   | Needs translated data, loses Swedish nuances   | Very good if translation is perfect                      |\n",
    " \n",
    " The survey results are based on searches on HuggingFace and google scholar with keywords (Swedish NER, Biomedical NER, etc), in order to see what models there are and what models have been used before.\n",
    "\n",
    "\n",
    "## Approach and Motivation\n",
    "In our approach, we want to use a Swedish Language-Model rather than translating the existing data into English. Although models like BioBERT offer very good performance in biomedical NER tasks, translation of clinical text can introduce errors and result in a loss of contextual information. This is particularly risky in the biomedical domain, where subtle differences in terminology can significantly impact the meaning of text. Additionally, as we are not biomedical experts, manually validating translations would be challenging.\n",
    "\n",
    "Therefore, our approach is to fine-tune an existing Swedish model for biomedical NER, using the Swedish Medical NER dataset provided. \n",
    "\n",
    "The three models found on HuggingFace which were relevant were: \n",
    "\n",
    "bert-base-swedish-cased (v1) - A BERT trained with the same hyperparameters as first published by Google.\n",
    "\n",
    "bert-base-swedish-cased-ner (experimental) - a BERT fine-tuned for NER using SUC 3.0.\n",
    "\n",
    "albert-base-swedish-cased-alpha (alpha) - A first attempt at an ALBERT for Swedish.\n",
    "\n",
    "## Our Choice\n",
    "Out of of these models, we will be using the base model (bert-base-swedish-cased (v1)). Although the experimental version is fine tuned for NER, we want to train it on specifically biomedical NER. The base model will be perfect for that since it's flexible and gives us more control of fine tuning it and has less prior bias. We will also not use the Albert version since it's a first attempt at it and still in alpha.\n",
    "\n",
    "Link for the KB bert models: https://huggingface.co/KB/bert-base-swedish-cased-ner \n",
    "\n",
    "Study which used KB/bert-base-swedish-cased and\n",
    "bert-base-multilingual-cased: (Although not related to biomedicine) https://aclanthology.org/2024.caldpseudo-1.7.pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is mandatory to maintain the headings for each task.  \n",
    "OPTIONALLY, you can use one level down (###) to organize subsessions of the assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use markdown cells like this one to include:\n",
    "- Discussion points.\n",
    "- References to specific sources of code that you might have used to solve the assignment.\n",
    "- General commentas and explanations about your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Always use comments in the code to document specific steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Välj modell, ladda ner dataset som står (https://huggingface.co/datasets/community-datasets/swedish_medical_ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section should contain the solution of task 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: \n",
    "\n",
    "Preprocess the Dataset for Token Classification\n",
    "Most likely, the data will be in token-label format. HuggingFace NER models expect:\n",
    "\n",
    "Input IDs\n",
    "Attention Masks\n",
    "Labels per token\n",
    "I can walk you through the actual code, but at a high level:\n",
    "\n",
    "Tokenize the sentences.\n",
    "Align the labels with the tokens.\n",
    "Format into a HuggingFace dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4:  Load the Model and Tokenizer och Fine-Tunea modellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Evaluera och kolla var den failade, vilka resultat hade den? etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section should contain:\n",
    "- Results.\n",
    "- Summary of best model performance:\n",
    "    - Name of best model file as saved in /models.\n",
    "    - Relevant scores such as: accuracy, precision, recall, F1-score, etc.\n",
    "- Key discussion points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Always use comments in the code to document specific steps"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
